{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a521891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # pattern line\n",
    "print(device) # originally, I'm not going to be able to use GPU, but I took assist of cloud GPUs.\n",
    "\n",
    "# What's the objetive?\n",
    "# Here I'm learning a few methods to create different types of tensors that may\n",
    "# help at the control of data the Large Language Model may use.\n",
    "# Basically, we're watching some High School Math in programming, although the concepts\n",
    "# of tensors are far away from High School."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f1c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01927161\n"
     ]
    }
   ],
   "source": [
    "# magic line. Prints cell time execution with a few parameters\n",
    "# %%time not currently working at my enviroment \n",
    "# possible return: CPU times: user 1.21 ms, sys: 44 Âµs, total: 1.25 ms\n",
    "# Wall time: 3.03 ms\n",
    "\n",
    "start_time = time.time() \n",
    "# matrix operations\n",
    "zeros = torch.zeros(1, 1)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")\n",
    "# OBS: While devolping this code at Google Colab, I got a little return\n",
    "# time for this code. Here, I usually don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e433c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.26713490\n",
      "2.16649580\n"
     ]
    }
   ],
   "source": [
    "# Testing GPU speed\n",
    "\n",
    "# creating torch matrices:\n",
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device) \n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "# As I said my current laptop does not have a GPU, so device='cpu',\n",
    "# but the results at Google Colab indicates that the GPU\n",
    "# is faster for parallel tasks like a 4x4 matrix.\n",
    "\n",
    "# Using 'cpu' (again, I use CPU both cases, but at Google Colab this made difference)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = (torch_rand1 @ torch_rand2) # @ is a reserved symbol at Python.\n",
    "# @ can only be used to correct libraries that allows matricial multiplication.\n",
    "# I can recreate the logic of matricial multiplication with lists, but it's less precise.\n",
    "# Torch uses C++ (which has arrays) to do it.\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# land = np.multiply(np_rand1, np_rand2) - this is element-wise not matricial\n",
    "# multiplication. Professor made a mistake here. You can directly use PyTorch\n",
    "# matricial multiplication system, just do not use \".to(device)\", (if device == 'gpu')\n",
    "# and you'll test the cu speed.\n",
    "\n",
    "land = (np_rand1 @ np_rand2)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")\n",
    "\n",
    "# IMPORTANT: torch.rand(x, y, z...) creates a tensor of dimension N, being\n",
    "# N the number of parameters within \".rand()\".\n",
    "# The number of elements inside the tensor = x . y . z . ... . n (the product\n",
    "# of all parameters).\n",
    "# Now, consider that you're using PyTorch library, which is wrote in C code.\n",
    "# In C language, every float \"costs\" 4 bytes (usually).\n",
    "# For a 6D tensor, like (100, 100, 100, 100, 100) the memory used would be:\n",
    "# 4 (bytes) x 10^10 (elements) = 4TB. So, take care!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5366f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# This part of the code is, basically, the strutcture that sustains \n",
    "# mutation rate of NEAT algorithm. \n",
    "\n",
    "# First step: define a variable that creates a float tensor, with values\n",
    "probabilities = torch.tensor([0.1, 0.9]) \n",
    "# The values don't need to match, when summed, 1, but it's more accurate\n",
    "# to do like that.\n",
    "\n",
    "# Second step: use the probability generator method of PyTorch to storage\n",
    "# the samples. This could be the part of NEAT algorithm that iniatializes the\n",
    "# mutation rate of some parameters.\n",
    "samples = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "# Generic torch.multinomial:\n",
    "# torch.multinomial(tensor_here, number_of_samples_defined_here, repetition_of_samples_yes_or_not)\n",
    "# OBS: if replacement=False, then num_samples = len(probabilities) or it won't work.\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a46b6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat method to append tensors.\n",
    "tensor = torch.tensor([1, 2, 3, 4]) # unidimensional tensor\n",
    "\n",
    "output = torch.cat((tensor, torch.tensor([2, 3])), dim=0)\n",
    "output\n",
    "# Note: Jupyter Notebook print anything at the last line, that's\n",
    "# why I don't have to type print(output) (this is a rude explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645e8eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tril(torch.ones(5, 5)) # creates a triangle matrix\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1595b526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(5,5)) # creates an inverted triangle matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10d6c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important\n",
    "# Breaking down the code:\n",
    "\n",
    "out = torch.zeros(5, 5).masked_fill_(torch.triu(torch.ones(5, 5)) == 1, float('-inf'))\n",
    "# \"torch.zeros(5,5)\", creates a tensor 5 x 5 filled with zeros.\n",
    "# \".masked_fill_\", creates an instance that modifies in-place a tensor.\n",
    "# In this case, we're chain methods, so the tensor being modified is the quoted one.\n",
    "# \".masked_fill_(parameter a, parameter b)\" the parameters you can use are:\n",
    "# A matrix, that MUST be the same size as the matrix you're going to mask (it wouldn't make sense\n",
    "# if it was different), and the value that will correspond to True. You can choose any value.\n",
    "# In this case, all values within the triangle matrix created that are == 1 will be consider True.\n",
    "# Within masked_fill_, True values are modified. False values stay as they are.\n",
    "# Parameter b --> indicates what will be the new value for the \"True\" values inside the masked matrix.\n",
    "# After that, masked_fill_ will apply the changes at the matrix the method is being used.\n",
    "# Note: There's also masked_fill (withoout the last underline), which applys the method creating a new matrix\n",
    "# instead of modifying the previous. In this case, seems to make no difference what method you're going to use,\n",
    "# once I'm applying the method at a same variable, which basically means \"masked_fill\" would overwrite the content, just\n",
    "# like masked_fill_\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7626d6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take every element inside the tensor and uses it as an expoent for Euler number (2,7 aproximately)\n",
    "torch.exp(out)\n",
    "# In this case, '-inf' bring us close to 0. e^-inf = 0\n",
    "# andddd... e^0 = 1. So, that's the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a8a792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix transpose, matrix transposition.\n",
    "inp = torch.zeros(2, 3, 4) # 2 matrices, 3 lines each one, 4 columns each one\n",
    "out = inp.transpose(0, 2) # 0 and 2 are indexes\n",
    "# breaking down \".transpose\"\n",
    "# The parameters are indexes of the tensor you're applying this method.\n",
    "# In this case, you're applying this method to a tensor (2, 3, 4), as quoted.\n",
    "# \"0\" means the first index and \"2\" the third. So, the tensor (2, 3, 4) will be transposed\n",
    "# to (4, 3, 2). Basically, we're swapping the first and the third dimesion.\n",
    "# This will bring us back 4 matrices (first dimension defined) with 2 columns and 3 rows.\n",
    "out.shape # prints the shape of the tensor (not the tensor itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26117e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) tensor([4, 5, 6]) tensor([7, 8, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "print(tensor1, tensor2, tensor3)\n",
    "\n",
    "# Stack the tensors along a new dimension\n",
    "# Important: Tensor must be the same size. \n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "stacked_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ee3bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 10., 10.])\n",
      "tensor([-10.7175,   4.5652,  -4.3617], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "sample = torch.tensor([10., 10., 10.]) # tensor that serves as an input.\n",
    "print(sample)\n",
    "# Imagine a NEAT algorithm. \n",
    "# For any input, there's a transformation function.\n",
    "# This is the case o \".Linear\". It applies a linear transformation.\n",
    "# Randomly (but you can choose manually) generates weights for the inputs.\n",
    "# Then makes WEIGHT x INPUT. The formula is:\n",
    "# L(input) = input . weight^t + bias (in this case, bias = 0)\n",
    "# Note: weight^t = transpose matrix of weight.\n",
    "linear = nn.Linear(3, 3, bias=False)\n",
    "print(linear(sample))\n",
    "# After that, we have an activation function, like tanh.\n",
    "# How to read it:\n",
    "# nn.linear(how_much_inputs_it_will_receive, how_much_outputs, bias)\n",
    "# howm_much_out_puts >= 0 and do not depend of the number of inputs.\n",
    "# how_much_inputs_it_will_receive must match the exact number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b3204a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(tensor1)\n",
    "# Used to give back the probability of the elements you gave to it.\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "# The higher the element, higher the probability.\n",
    "# The sum at the output == 1\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d89fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 5)\n",
      "tensor([[ 1.8071,  1.4398,  0.9471, -0.0209, -0.6883],\n",
      "        [-2.2881,  0.6217, -1.0466,  1.4214,  0.7874],\n",
      "        [-0.4318,  0.5044, -1.4173, -0.0445, -0.2961],\n",
      "        [ 0.9745, -1.8651, -0.1608,  0.3834,  1.1423],\n",
      "        [ 1.8071,  1.4398,  0.9471, -0.0209, -0.6883]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create an embedding layer with 10 'words' and each word represented by a 5-dimensional vector\n",
    "embedding_layer = nn.Embedding(10, 5)\n",
    "print(embedding_layer)\n",
    "\n",
    "# Create a tensor of integers representing word IDs\n",
    "word_ids = torch.tensor([1, 2, 4, 5, 1])\n",
    "\n",
    "# Get embeddings for the word IDs\n",
    "word_embeddings = embedding_layer(word_ids)\n",
    "\n",
    "print(word_embeddings)\n",
    "# The 5-dimensional vector means, in Python terms, a list with 5 elements.\n",
    "\n",
    "# Why Do We Use It?\n",
    "# The method \"nn.Embedding\" can be used to associate human-defined parameters for \n",
    "# words in a way that the computer can understand. In this case,\n",
    "# we're creating a dictionary for 10 words. In this dictionary, we have \n",
    "# 5 definitions (the 5-dimensional vectors). The numbers that are generated,\n",
    "# as the model gets more and more trained, will be closer for words that\n",
    "# have similar meanings. \n",
    "# For example:\n",
    "# Parameter 1 = Semantic meaning - the strict dictionary definition.\n",
    "# Parameter 2 = Emotional meaning.\n",
    "# Parameter 3 = Level of formality vs. informality.\n",
    "# Parameter 4 = Length of the word.\n",
    "# Parameter 5 = Usage (how frequently the word is used).\n",
    "# For the model, these parameters are just numbers, but with proper logic,\n",
    "# the model will start to make words that are longer have a closer value for parameter 4,\n",
    "# while \"love\" and \"hate\" will have greater distance in parameter 2, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51764653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: PyTorch does not multiply float with integers. \n",
    "# Therefore, while building the Large Language Model, rather use floating numbers \n",
    "# (which guarantes more precision) than integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c3f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "2 3 5\n",
      "torch.Size([5, 3, 2])\n",
      "torch.Size([30, 1, 1, 1, 1, 1])\n",
      "10\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "# unpacking tensor dimensions and then remodeling it.\n",
    "a = torch.rand(2, 3, 5) # tensor dimensions\n",
    "print(a.shape)\n",
    "x, y, z = a.shape\n",
    "a = a.view(z, y, x)\n",
    "print(x, y, z)\n",
    "print(a.shape)\n",
    "a = a.view(30, 1, 1, 1, 1, 1)\n",
    "print(a.shape)\n",
    "# Not possible: \n",
    "# You can't remodel it with dimensions that will have less\n",
    "# elements than in the begin neither more elements.\n",
    "# But you can add neutral dimensions (1, basically).\n",
    "\n",
    "# Others possibilities:\n",
    "a = torch.rand(1, 2, 3, 4, 5, 10)\n",
    "l = a.shape[5]\n",
    "print(l)\n",
    "l, m, _, _, _, _ = a.shape\n",
    "print(l, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bcf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudagpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
